Этот метод об оценке вклада каждого признака в предсказания модели.
Здесь можно выделить несколько основных подходов:
### На основе уменьшения ошибки:

  Для каждого признака измеряется, насколько уменьшается ошибка (например, MSE или Gini) при его использовании для разбиения в дереве. Признаки, которые чаще используются для разбиения и сильнее уменьшают ошибку, считаются более важными. Используют преимущественно в бустинге, т.к. легче отслеживать ошибку.

Покажу как обычно получают в виде кода (Но скорее абстрактно, опущу ненужное для примера):
``` python
from xgboost import XGBClassifier
from sklearn.datasets import load_iris

data = load_iris()
X = data.data
y = data.target

model = XGBClassifier()
model.fit(X, y)

importances = model.feature_importances_
```

Если вывести importances, увидим следующее:
``` console
[0.00959796 0.01645038 0.6765859 0.2973658]
```

Пример для случайного леса:
- Для каждого дерева вычисляется важность признаков на основе уменьшения ошибки.
- Итоговая важность признака — это среднее значение по всем деревьям.

### На основе перестановок:

  Для каждого признака измеряется, насколько ухудшается качество модели, если значения этого признака случайно переставить. Чем сильнее ухудшение, тем важнее признак. Особенно популярен для нейросетей: он простой, работает с любой нейросетью.

Для pytorch есть библиотека для интерпретации моделей. Называется **Captum**.
``` python
from captum.attr import FeatureAblation

model = SimpleNN() # Просто предположим, что такое сделали уже

ablator = FeatureAblation(model)

attributions = ablator.attribute(X_test, target=0) # target = 0 показывает какой выходной нейрон по счету мы будем проверять
```

attributions это `tensor([[ 0.1234, -0.5678,  0.9101, -0.1121,  0.3141]])`, где положительные увеличивают вход, а отрицательные уменьшают.

### На основе весов:

  В линейных моделях важность признака может быть оценена по абсолютному значению его коэффициента. 

Супер простой пример:
``` python
from sklearn.linear_model import LinearRegression
from sklearn.datasets import load_iris

data = load_iris()
X = data.data
y = data.target

model = LinearRegression()
model.fit(X, y)

coefficients = model.coef_
```

coefficients здесь будет следующий: `array([-0.11190585, -0.04007949,  0.22864503,  0.60925205])`

Чем больше значение - тем больше ценится признак, но стоит перед этим обработать данные (нормализовать), иначе исказится восприятие важности.


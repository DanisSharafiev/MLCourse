Этот метод об оценке вклада каждого признака в предсказания модели.
Здесь можно выделить несколько основных подходов:

- На основе уменьшения ошибки:
  Для каждого признака измеряется, насколько уменьшается ошибка (например, MSE или Gini) при его использовании для разбиения в дереве. Признаки, которые чаще используются для разбиения и сильнее уменьшают ошибку, считаются более важными.
  
- На основе перестановок 
  Для каждого признака измеряется, насколько ухудшается качество модели, если значения этого признака случайно переставить. Чем сильнее ухудшение, тем важнее признак.
  
- На основе весов
  В линейных моделях важность признака может быть оценена по абсолютному значению его коэффициента.

Пример для случайного леса:
- Для каждого дерева вычисляется важность признаков на основе уменьшения ошибки.
- Итоговая важность признака — это среднее значение по всем деревьям.

Покажу как обычно получают в виде кода (Но скорее абстрактно, опущу ненужное для примера):
``` python
from xgboost import XGBClassifier
from sklearn.datasets import load_iris

data = load_iris()
X = data.data
y = data.target

model = XGBClassifier()
model.fit(X, y)

importances = model.feature_importances_
```


perm importance neural networks

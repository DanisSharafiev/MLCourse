Перейдем к делению классов. Для чего это нужно? Допустим, мы хотим обучить какую-то модель, возникает вопрос: как проверить насколько она эффективна?

Проверять на том же датасете, где и обучали - нерационально. Мы ведь с помощью этого датасета уменьшаем нашу loss функцию, естественно алгоритм будет максимально пытаться подходить под все данные. Но мы не можем ничего сказать о том, как будут предсказываться новые, поэтому мы разделяем случайным образом на тренировочную и тестовую. Таким образом мы создаем "неизвестные" данные для алгоритма: мы сможем проверить хорошо ли предсказывает наша модель. Еще делят на Validation из тестовой (обычно пополам). Мы способны использовать регуляризации, оценить обобщающие способности, подобрать гиперпараметры, не затрагивая тестовую выборку.

test_size это то, сколько мы возьмем от датасета, где 1 = 100%, 0.2 = 20% и т.п. Первый аргумент обозначают признаки, а второй - целевую переменную.

``` python
import pandas as pd
data = [{"Chicken": "Banana", "Banana" : "Chicken"},
		{"Chicken": "Chicken", "Banana" : "Banana"}]
```

``` python
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    data["Chicken"], data['Banana'], test_size=0.2, random_state=42)
```

И здесь можем поделить еще тестовую пополам, создавая валидационную выборку.

``` python
X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42)
```

Для задач классификации бывает нужно сбалансировать классы для тренировочной и тестовой выборки: чтобы не было такого, что у трейна будет только 1 класс, а у теста только второй. Используем stratify на нужном

``` python
X_train, X_test, y_train, y_test = train_test_split(
    data["Chicken"], data['Banana'], test_size=0.2, 
    random_state=42, stratify = data['Banana'])
```
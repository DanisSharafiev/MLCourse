# Куда собирать данные

Теперь поговорим о том, как собирают данные и в каком виде. В данный момент я буду покрывать только сбор данных для DataFrame (Грубо говоря просто таблица) из pandas. Как мне кажется, так будет легче для изучения с полного нуля, с его помощью довольно легко анализировать данные. Для уверенности будет лучше заглянуть перед этой частью конспекта в "Источник данных".

# Файлы

Самые распространенные форматы файлов для работы csv, xlsx.

Чтобы открыть их в питоне в качестве DataFrame достаточно знать путь к файлу:

``` python
import pandas as pd
df1 = pd.read_excel('file.xlsx')
df2 = pd.read_csv('file.csv')
```

Вот и все, первый DataFrame прочитан, но может возникнуть вопрос, а что, если у меня есть два файла, которые как-то связаны? Допустим по id или любым другим способом. В таких случаях мы можем соединить их при помощи join (аналогия с базами данных).

``` python
df3 = df.merge(df1, df2, on = "id", how = "inner")
```

Таким простым образом мы соединили два таблицы в одну по ключу id с помощью inner join. Аргумент how принимает в себя inner, left, right, full (или же outer) и cross, когда on может хранить список, чтобы соединять по нескольким столбцам сразу. Простой пример:

``` python
df3 = pd.merge(df1, df2, on=['id', 'name'], how='full')
```

Также кто-то может захотеть добавить какой-то дополнительный столбец из уже имеющихся, это можно сделать несколькими способами:

#### 1. df.apply()

Применяет функцию к каждой строке/столбцу DataFrame

В полезные аргументы попадают
- func: какая-то функция которая будет применена
- axis: по стобцу (axis = 0) или по строке (axis = 1)
- raw: False -> pd.Series, True -> массив numpy

Пример:

``` python
def f(row):
	if row['value'] < 10:
		return "bedniy"
	else:
		return "bogatiy"

df["class"] = df.apply(f, axis = 1)
```

#### 2. df.iterrows():

Позволяет итерировать по строкам DataFrame.

Аргументов нет

Пример:

``` python
df["status"] = ''

for index, row in df.iterrows():
	if row["burger"] == "done" and row["french fries"] == "done":
		df.at[index, 'status'] = "done"
	else:
		df.at[index, 'status'] = "in process"
```

#### 3. df.loc\[\]

Позволяет задавать значения для нового столбца на основе условий, используя индексирование. Довольно эффективный.

Аргументы:
- row_labels: метки или условие для выбора строк.
- column_labels: метки для выбора столбцов

Пример:

``` python
df.loc[df['age'] < 18, 'skill_issue'] = "here"
df.loc[df['age'] >= 18, 'skill_issue'] = "still_here"
```

#### 4. df.mask()

Заменяет значения, если условие выполнено. Довольно неудобный для создания нового столбца.

Аргументы:
- cond: Условие, при котором значения заменяются.
- other: Значение, если cond выполнено
- inplace: При True модифицирует DataFrame на месте.
- axis: По стобцу (axis = 0) или по строке (axis = 1).

Пример:

``` python
df['age'] = "Stariy"
df['age'] = df['age'].mask(df['age'] < 20, "molodNYAk")
```

# Базы данных

Базы данных это один из самых часто используемых источников для получения данных для последующей обработки.

Возьмем довольно простой пример того, как передается вся таблица через get_all_users()

``` python
from fastapi import FastAPI
from sqlalchemy import create_engine, text

engine = create_engine("sqlite:///./users.db")

app = FastAPI()

# Не будем затрагивать лишнюю реализацию для ясности

@app.get("/users")
def get_all_users():
    with engine.connect() as connection:
        result = connection.execute(text("SELECT * FROM users"))
        users = [dict(row) for row in result]
    return users
```

Пусть backendеры занимаются своей работой, а с нашей стороны остается только принять и обработать, а это довольно просто:

``` python
import requests
import pandas as pd

url = "http://localhost:8000/users"
data = requests.get(url).json()
df = pd.DataFrame(data)
```

Вот мы и прочитали таблицу из базы данных в DataFrame. Может быть такое, что вам захочется добавить каких-то еще строчек, 
Стажерский набор
### Данные

Сбор данных:
- Explicit feedback - умышленно (рейтинг, лайк, репост)
- Implicit feedback - на бекграунде (время просмотра, клики, история и т.п.)

Тип хранение:
- SQL или NoSQL или любые другие бдшечки. Можно использовать Redis для сохранения предсказаний 

### Рекомендательные системы:

##### **Collaborative Filtering** (User-based, Item-based)

Разделяется на 2 типа, User-based и Item-based

- **User-based:**
Построенно на схожести пользователей (если у меня и у другого человека много совпадений, то мне могут предложить то, что смотрел он, но не смотрел я)

**Cosine similarity, Pearson correlation**
**K-nearest neighbors**
**Weighted average**

- **Item-based:**
Этот метод предсказывает одинаковые предметы основанные на предыдущих оценках объектов.

- Memory-based:
SVD, ALS и т.д.

**Cosine similarity**
**Adjusted cosine similarity**


Collaborative Filtering страдает от 3 основных проблем:
1. Cold start - что предлагать новым, только зарегистрированным пользователям
2. Масштабируемость - с ростом пользователей и объектов, становится сложнее высчитывать рекомендации.
3. Sparsity - пользователи в основном оценивают только очень малую часть объектов из имеющихся, из-за чего много пустых значений

##### **Content-based filtering**

Построено на атрибутах продукта (жанры, одинаковые артикли и т.п.) и предпочтениях пользователя (любит хорроры - получит чаще их)

Здесь тоже выделяются 3 проблемы:
- Filter Bubble - рекомендует только похожее
- Limited Discovery - нет неожиданных находок
- Feature Engineering - нужно извлекать как-то признаки

TF-IDF + Cosine similarity
Feature-Based Similarity
User profile Building

##### **Matrix Factorization** (SVD, ALS)
- SVD

Explicit feedback (от 1 до 5 например)
Меньше памяти доступно
Online learning
Работает на SGD
Обновляет каждый рейтинг отдельно
Медленно сходится
Может застрять в локальном минимуме
Для Implicit feedback нужна модификация до SVD++
Biases явно моделируются

- ALS

Особенно популярен для implicit feedback.

Подходит для implicit feedback, больших датасетов, batch processing, collaborative filt.
Преимущества: масштабируется, работает с разреженными данными, determenistic.
Проблемы: Real-time, Content-based, Cold-start, Memory intensive, Linear complexity

##### **Метрики оценки**: Precision@K, Recall@K, NDCG, MAP

Precision@K = relevant_items_in_top_k/k
Recall@K = relevant_items_in_top_k/total_relevant_items

``` python
dcg_k = sum(rel_i / log2(i + 1) for i in range(k))
ndcg_k = dcg_k / ideal_dcg_k
```

##### **Бизнес метрики**

Conversion_rate = purchases / recommendations_shown
Revenue_per_user = total_revenue / unique_users
Click_through_rate = clicks / impressions
Session_duration = mean(logout_time - login_time)

##### **Cold start problem** и способы его решения

Разделяется на три типа:
- New User Cold Start - данных о пользователе нет, поэтому мы не знаем, что ему предложить.
- New Item Cold Start - объект никто еще не трогал, поэтому мы не знаем, кому может понравиться.
- New System Cold Start - ваще никаких данных нет

Как решать эти проблемы?
Новым пользователям можно предлагать популярные фильмы (items) в регионе, проводить опрос при регистрации для поиска любимых жанров и т.п. Можно еще импортировать данные из других сервисов, что поможет базово понять, что рекомендовать.

Подходы:
1. Popularity-based. Простые и всегда работают, но не персонализированы, имеют проблему filter bubble.
2. Demographic-based. Используем данные о самом пользователе по типу возраста, пола, локации, профессии, гаджетов и т.п.
3. Content-based. Собираем любым способом информацию о пользователе: explicit, implicit feedback. И импорт из других сервисов.
4. Knowledge-based. Основывается на внешней информации (в основном не зависит от пользователя напрямую) по типу сезонности, отелей по бюджету и локации, по недавним новостям.
5. Hybrid. Комбинирует несколько способов в одну. Просто перемешивает и дает какой-то вес определенным системам. Например, 0.3 на demographic-based, 0.4 на popularity-based, 0.3 на content-based. 

### RAG пайплайны (базово):

RAG pipeline: 
`query -> encode -> retrieve top-k -> rerank -> generate`
`dataloader -> splitter -> retriever -> generation`
##### Понимание концепции **Retrieval-Augmented Generation**

###### Retrieval (Извлечение информации)

Что делает:
1. Находит релевантные документы или данные
2. Использует векторные базы данных для поиска похожих документов

Что нужно:
1. Vector search Поиск по векторным представлениям текста
2. Embedding Models Преобразование текста в векторы (Bert, sentence-transformers)
3. FAISS/Pinecone/Qdrant БД для хранения и поиска векторов

FAISS
Принцип работы
Индексы:
IndexIVF
Работает на принципе кластеризации данных. K-means создает центроиды, входной эмбеддинг сравнивается со всеми центроидами. nprobe обозначает количество рассматриваемых кластеров, потом все эмбеддинги из всех nprobe кластеров сливаются в один список и ранжируются.
IndexFlatL2/IndexFlatIP
Супер простой, данные хранятся просто так. Обучать ничего не надо, мы просто попарно сравниваем расстояние от вектора до остальных векторов и потом ранжируем. L2 использует евклидово расстояние, а IP Inner product, скалярное произведение.
IndexLSH
Используются хэш функции, которые приводят эмбеддинги в общие диапазоны. Делается так, чтобы схожие эмбеддинги попадали с большей вероятностью в один и тот же хэш-бакет. Потом просто сравниваем и ранжируем.
IndexPQ
Эмбеддинг разбивается на m частей, для каждого под-вектора существует "кодовая книга" (в основном на K-means), по которым мы уже будем пробегаться и сравнивать все эмбеддинги с исходным и ранжировать. Для m частей бы пробежимся по m разным закодированным значениям под-векторов, благодаря чему получим похожие вектора.

Часто используют IVF + PQ:
IVF создаем кластеры, а внутри этих кластеров используем PQ для ускорения.
	
###### Generator (Генерация текста)

Что делает:
1. Генерирует ответ на основе найденной информации
2. Использует языковые модели (e.g. GPT, T5)

Основные технологии:
- LLM: GPT-4, Claude 3.7, Deepseek-R1 etc.
- Prompt Templates: Форматирование ввода для генерации ответа.

###### Pipeline (Объединение Retriever и Generator)

Как работает:
- Пользователь отправляет запрос
- Retriever получает топ-K релевантных документов
- Generator создает ответ, используя контекст из этих документов

##### Chunking strategies

###### Fixed-size Chunking
Разделение текста на куски фиксированной длины, например 512, 1024 токенов и т.д.
Размер определяется ограничением модели

###### Sentence-based Chunking
Разделение текста на предложения с помощью NLP-библиотек
Каждая часть объединяет несколько предложений, пока не достигнет лимит токенов

###### По параграфам
Разделение текста на параграфы
Соединяются в одну часть до достижения лимита токенов.

###### Семантическое разделение
Использует NLP для определения тематических блоков.
Выделяет части текста, которые имеют схожую тематику или смысл.

###### Content-aware
Учитывает структуру документа(Заголовки, списки, таблицы, цитаты)
Разделяет текст на логические блоки

###### Dynamic Chunking
Адаптивное определение размера чанковв на основе длины предложений/параграфов и т.п.
Увеличивает размер кусков, если текст короткий, и уменьшает, если длинный.



Contextual Compressors & Filters
Multi-Query Retrieval
Создаем дополнительно несколько вопросов с помощью LLM для поиска, закидываем в один список и ранжируем(последнее необязательно)
RAG-Fusion
Как Multi-Query Retrieval только делаем супер умное ранжирование типа по частоте появлений разных запросов, всякие метрики, ранжирование, выбор топ-N, повторный поиск по необходимости. (называется fusing)
Multimodal RAG
RAPTOR



![[Pasted image 20250606004915.png]]

![[Pasted image 20250606004917.png]]


### TF-IDF (Term Frequency-Inverse Document Frequency)
Статистическая мера
Превращает слово в цифру, чем больше - тем более значимая.
$$
TF(t,d) = \frac{\text{(Количество появлений термина t в документе d)}}{\text{(Общее количество терминов в документе d)}}
$$
$$
IDF(t, D) = \log _{e} \frac{\text{(Общее количество документов)}}{\text{(Количество документов с термином t в них)}}
$$
$$TF-IDF(t,d,D) = TF(t,d) * IDF(t, D)$$

Плюсы: простой (легко запустить), не требует обучения
Минусы: не понимает смысла слова (контекст, порядок), плохо масштабируется 

### BM25

Разработана для систем ранжирования документов по поиску

$$
\text{BM25}(Q, D) = \sum_{i=1}^{n} \text{IDF}(q_i) \cdot \frac{\text{TF}(q_i, D) \cdot (k_1 + 1)}{\text{TF}(q_i, D) + k_1 \cdot \left(1 - b + b \cdot \frac{|D|}{\text{avgdl}}\right)}

$$

- $Q = \{q_1, q_2, \dots, q_n\}$ — запрос, представленный как набор терминов.
    
- $D$ — документ, для которого вычисляется релевантность.
    
- $\text{TF}(q_i, D)$ — частота термина $q_i$ в документе $D$.
    
- $|D|$ — длина документа $D$ (количество слов).
- $\text{avgdl}$ — средняя длина документов в коллекции.
- $k_1$ и $b$ — свободные параметры, которые настраиваются (обычно $k_1 \in [1.2, 2.0]$, $b \in [0.5, 0.75]$).
